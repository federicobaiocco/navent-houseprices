{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.lang.es.stop_words import STOP_WORDS\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline \n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import category_encoders as ce \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_sm', disable=['ner','parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\", parse_dates=['fecha'])\n",
    "val = pd.read_csv(\"test.csv\", parse_dates=['fecha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TituloDescripcionConcat( BaseEstimator, TransformerMixin ):\n",
    "    '''\n",
    "    Se concatena la columna texto con la columna descripccion en una nueva columna llamada \"text\"\n",
    "    '''\n",
    "    def __init__( self ):\n",
    "        pass\n",
    "      \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    def transform( self, X, y = None ):\n",
    "        X.descripcion = X.descripcion.fillna(\" \")\n",
    "        X.titulo = X.titulo.fillna(\" \")\n",
    "        X[\"text\"] = X[\"titulo\"] + \" \" + X[\"descripcion\"]\n",
    "        X = X[[\"text\"]]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HtmlCleaner( BaseEstimator, TransformerMixin ):\n",
    "    '''\n",
    "    Se limpia todo el html que hay en la columna text\n",
    "    '''\n",
    "    def __init__( self ):\n",
    "        pass\n",
    "    \n",
    "    def clean_html(self,raw_html):\n",
    "        soup = BeautifulSoup(raw_html)\n",
    "        text = soup.get_text()\n",
    "        return text\n",
    "      \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    def transform( self, X, y = None ):\n",
    "        X.text = [self.clean_html(text) for text in X.text]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "class TextCleaner( BaseEstimator, TransformerMixin ):\n",
    "    '''\n",
    "    Se limpian stopwords, numeros, puntuaciones y se convierten las palabras a raiz\n",
    "    '''\n",
    "    def __init__( self ):\n",
    "        pass\n",
    "    \n",
    "    def cleanup_text(self, doc):\n",
    "        txt = [token.lemma_ for token in doc if not token.is_stop]\n",
    "        return ' '.join(txt)\n",
    "        \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    def transform( self, X, y = None ):\n",
    "        brief_cleaning = (re.sub(\"[^A-Za-z']+\",' ', str(row)).lower() for row in X['text'])\n",
    "        txt = [self.cleanup_text(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_threads = -1)]\n",
    "        X = pd.DataFrame({'text':txt})\n",
    "        return X.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterative imputer en los valores faltantes\n",
    "class MissingValuesImputer( BaseEstimator, TransformerMixin ):\n",
    "      \n",
    "    def __init__( self, features_to_impute ):\n",
    "        self._features_to_impute = features_to_impute\n",
    "        \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    def transform( self, X, y = None ):\n",
    "        imp = IterativeImputer(missing_values=np.nan, max_iter=30, random_state=42)\n",
    "        X[features_to_impute] = imp.fit_transform(X[features_to_impute])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropear columnas que no se usan\n",
    "class DropFeatures( BaseEstimator, TransformerMixin ):\n",
    "    \n",
    "    def __init__( self, features_to_drop ):\n",
    "        self._features_to_drop = features_to_drop \n",
    "      \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    def transform( self, X, y = None ):\n",
    "        for feat in self._features_to_drop:\n",
    "            if feat in X.columns:\n",
    "                X = X.drop(feat, axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder para las categorias\n",
    "class CategoryEncoder( BaseEstimator, TransformerMixin ):\n",
    "      \n",
    "    def fit( self, X, y = None ):\n",
    "        self.ciudad_te = ce.TargetEncoder().fit(X['ciudad'], X['precio'])\n",
    "        self.tipo_te = ce.TargetEncoder().fit(X['tipodepropiedad'], X['precio'])\n",
    "        self.prov_te = ce.TargetEncoder().fit(X['provincia'], X['precio'])\n",
    "        return self \n",
    "    \n",
    "    def transform( self, X, y = None ):\n",
    "        X['ciudad'] = self.ciudad_te.transform(X['ciudad'])\n",
    "        X['tipodepropiedad'] = self.tipo_te.transform(X['tipodepropiedad'])\n",
    "        X['provincia'] = self.prov_te.transform(X['provincia'])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tomo el a√±o de las fechas\n",
    "class DateTransformer( BaseEstimator, TransformerMixin ):\n",
    "      \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    def transform( self, X, y = None ):\n",
    "        X['ano'] = X.fecha.dt.year\n",
    "        X = X.drop('fecha',axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = ['lat','lng','direccion','idzona','id','titulo','descripcion','text','centroscomercialescercanos','escuelascercanas']\n",
    "\n",
    "features_to_impute = ['gimnasio', 'usosmultiples', 'piscina', 'tipodepropiedad','ciudad','provincia',\n",
    "                      'habitaciones','garages','banos','metroscubiertos','ano','metrostotales','antiguedad']\n",
    "\n",
    "text_preprocessing_pipeline = Pipeline( steps =   [ ('concat_titulo_descripcion',TituloDescripcionConcat()),\n",
    "                                                    ('clean_html',HtmlCleaner()),\n",
    "                                                    ('clean_text',TextCleaner()),\n",
    "                                                    ('bow', CountVectorizer(max_features = 800)),\n",
    "                                                    ('tfidf', TfidfTransformer()),\n",
    "                                                    ('reduce_dim',TruncatedSVD(n_components=30))\n",
    "                                                  ])\n",
    "\n",
    "features_preprocessing_pipeline = Pipeline( steps =   [ ('drop', DropFeatures(features_to_drop)),\n",
    "                                                        ('date_transformer',DateTransformer()),\n",
    "                                                        ('category_encoder',CategoryEncoder()),\n",
    "                                                        ('drop_target', DropFeatures(['precio'])),\n",
    "                                                        ('missing_values_imputer',MissingValuesImputer(features_to_impute)),\n",
    "                                                        ('scale', StandardScaler())\n",
    "                                                       ] )\n",
    "\n",
    "preprocessing = FeatureUnion([('generate_text_features',text_preprocessing_pipeline),\n",
    "                                ('preprocess_features', features_preprocessing_pipeline)\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df , test_df = train_test_split(train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df.precio\n",
    "y_test = test_df.precio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = preprocessing.fit_transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test = preprocessing.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "val_prep = preprocessing.transform(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#xgbr = xgb.XGBRegressor(learning_rate=0.03,max_depth=8, n_estimators=1000, n_jobs=-1, objective ='reg:squarederror')\n",
    "# dio 571894.0883116048 y 455510.3282945326\n",
    "#xgbr = xgb.XGBRegressor(learning_rate=0.03,max_depth=7, n_estimators=1000, n_jobs=-1, objective ='reg:squarederror')\n",
    "#dio 581319.3170221354 y 503285.17436894734\n",
    "xgbr = xgb.XGBRegressor(learning_rate=0.03,max_depth=11, n_estimators=1000, n_jobs=-1, objective ='reg:squarederror')\n",
    "xgbr.fit(X_train,y_train)\n",
    "xgbr_test_pred = xgbr.predict(X_test)\n",
    "xgbr_train_pred = xgbr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "551900.6034401042"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,xgbr_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241259.95551586914"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train,xgbr_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_preds = xgbr.predict(val_prep)\n",
    "subm = pd.DataFrame({'id':val.id, 'target':subm_preds})\n",
    "subm.to_csv(\"Xgbr_subm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.add(Dropout(0.2, input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(1024, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "#model.add(Dropout(0.1))\n",
    "#model.add(Dense(1024, activation='relu'))\\\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(adam, 'mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 192000 samples, validate on 48000 samples\n",
      "Epoch 1/512\n",
      "192000/192000 [==============================] - 60s 313us/step - loss: 715929.0484 - val_loss: 664835.1663\n",
      "Epoch 2/512\n",
      "192000/192000 [==============================] - 59s 308us/step - loss: 661189.3425 - val_loss: 631575.5838\n",
      "Epoch 3/512\n",
      "192000/192000 [==============================] - 59s 308us/step - loss: 644319.6019 - val_loss: 640189.3062\n",
      "Epoch 4/512\n",
      "192000/192000 [==============================] - 59s 308us/step - loss: 629804.9791 - val_loss: 627839.8376\n",
      "Epoch 5/512\n",
      "192000/192000 [==============================] - 63s 327us/step - loss: 624799.5332 - val_loss: 623231.2770\n",
      "Epoch 6/512\n",
      "192000/192000 [==============================] - 53s 278us/step - loss: 615122.2919 - val_loss: 615831.7342\n",
      "Epoch 7/512\n",
      "192000/192000 [==============================] - 63s 330us/step - loss: 610190.6102 - val_loss: 609829.4081\n",
      "Epoch 8/512\n",
      "192000/192000 [==============================] - 74s 384us/step - loss: 604594.8617 - val_loss: 607241.5522\n",
      "Epoch 9/512\n",
      "192000/192000 [==============================] - 61s 320us/step - loss: 601171.2727 - val_loss: 613124.4718\n",
      "Epoch 10/512\n",
      "192000/192000 [==============================] - 63s 328us/step - loss: 596303.5939 - val_loss: 603351.9618\n",
      "Epoch 11/512\n",
      "192000/192000 [==============================] - 63s 327us/step - loss: 592504.1976 - val_loss: 600640.1322\n",
      "Epoch 12/512\n",
      " 14080/192000 [=>............................] - ETA: 1:59 - loss: 586953.2009 ETA: 2:20"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train, \n",
    "          batch_size= 256, \n",
    "          epochs = 20, \n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=[keras.callbacks.EarlyStopping(patience=15)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_preds = model.predict(val_prep).ravel()\n",
    "subm = pd.DataFrame({'id':val.id, 'target':subm_preds.ravel()})\n",
    "subm.to_csv(\"NN_subm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 42min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "random_forest = RandomForestRegressor(max_depth=20, n_estimators=1000, min_samples_leaf=20, n_jobs=-1)\n",
    "random_forest.fit(X_train, y_train)\n",
    "pred_train = random_forest.predict(X_train)\n",
    "pred_test = random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 519380.82190427894\n",
      "Test 618099.7361454667\n"
     ]
    }
   ],
   "source": [
    "print(\"Train \"+str(mean_absolute_error(y_train, pred_train)))\n",
    "print(\"Test \"+str(mean_absolute_error(y_test, pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_preds = random_forest.predict(val_prep)\n",
    "subm = pd.DataFrame({'id':val.id, 'target':subm_preds})\n",
    "subm.to_csv(\"Rf_subm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.03, max_depth=100,\n",
       "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=1000, n_jobs=-1, num_leaves=31, objective=None,\n",
       "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lgbm = lgb.LGBMRegressor(max_depth=100,\n",
    "                        learning_rate=0.03,\n",
    "                        n_estimators=1000)\n",
    "lgbm.fit(X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric='l1',\n",
    "        verbose=False,\n",
    "        early_stopping_rounds=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = lgbm.predict(X_test, num_iteration=lgbm.best_iteration_)\n",
    "pred_train = lgbm.predict(X_train, num_iteration=lgbm.best_iteration_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 553286.0534873547\n",
      "Test 589477.0477098798\n"
     ]
    }
   ],
   "source": [
    "print(\"Train \"+str(mean_absolute_error(y_train, pred_train)))\n",
    "print(\"Test \"+str(mean_absolute_error(y_test, pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_preds = lgbm.predict(val_prep)\n",
    "subm = pd.DataFrame({'id':val.id, 'target':subm_preds})\n",
    "subm.to_csv(\"LGBM_subm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(max_depth=12, n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 25min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=0.1, loss='ls', max_depth=12,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                          n_iter_no_change=None, presort='deprecated',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_test_pred = gbr.predict(X_test)\n",
    "gbr_train_pred = gbr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "567722.0232116096"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,gbr_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121181.29940531179"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train,gbr_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_preds = gbr.predict(val_prep)\n",
    "subm = pd.DataFrame({'id':val.id, 'target':subm_preds})\n",
    "subm.to_csv(\"GBR_subm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('xgbr',xgbr),\n",
    "              ('gbr',gbr),\n",
    "              ('lgbm',lgbm),\n",
    "              ('random_forest',random_forest)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = xgb.XGBRegressor(learning_rate=0.03,max_depth=4, n_estimators=500, n_jobs=-1, objective ='reg:squarederror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_reg = StackingRegressor(estimators=estimators, final_estimator=final )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "stacking_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_test_pred = stacking_reg.predict(X_test)\n",
    "s_train_pred = stacking_reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test,rf_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_train,rf_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_preds = stacking_reg.predict(val_prep)\n",
    "subm = pd.DataFrame({'id':val.id, 'target':subm_preds})\n",
    "subm.to_csv(\"Stacking_subm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
